{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "88559ec8-4133-40c0-9dc3-f1a572078b22",
        "_uuid": "179a652fa10a7015e4120919e9b8821731eb4a5c"
      },
      "cell_type": "markdown",
      "source": "# Introduction\n\nThis is the companion workbook to [this lesson on topic modelling in R](https://www.kaggle.com/rtatman/nlp-in-r-topic-modelling/). Read through the lesson and then come here to complete the exercises so all your work is in one central place.\n\nFor this workbook we'll be working with a dataset of text from various types of false news stories.\n____\n\n**Remember**: If you want to share this notebook you need to make it public so that other people can see it. You can do that by forking this notebook and then selecting \"public\" on the drop-down menu to the left of the \"Publish\" button.\n____\n# Table of Contents: \n\n* [Setting up our environment](#Setting-up-our-environment)\n* [Unsupervised topic modeling with LDA](#Unsupervised-topic-modeling-with-LDA)\n* [Pre-processing text for more informative models](#Pre-processing-text-for-more-informative-models)\n* [Supervised topic modelling with TF-IDF](#Supervised-topic-modelling-with-TF-IDF)\n___"
    },
    {
      "metadata": {
        "_cell_guid": "7039aba3-8677-40f4-8f58-10431e42bca4",
        "_uuid": "9cec883a8c78399bda453d23cc63eb8094d6ce60"
      },
      "cell_type": "markdown",
      "source": "# Setting up our environment\n___\n\nBefore we get started, we need to make sure our R environment is ready. We'll need to read in the packages and data we'll be using. Here, I've done this step for us."
    },
    {
      "metadata": {
        "_cell_guid": "181c612c-5a2d-4788-b920-8c663a2bd8de",
        "_uuid": "152cc5b572d3f7280aa6b6770ca9a6830174c90d",
        "trusted": true,
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "# read in the libraries we're going to use\nlibrary(tidyverse) # general utility & workflow functions\nlibrary(tidytext) # tidy implimentation of NLP methods\nlibrary(topicmodels) # for LDA topic modelling \nlibrary(tm) # general text mining functions\nlibrary(SnowballC) # for stemming\n\n# read in our data\ntexts <- read_csv(\"../input/fake.csv\")\nenglish_texts <- filter(texts, language==\"english\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7a98bcd9-a635-43d1-9113-ec5c837e3205",
        "_uuid": "b79534083b71590f30bbc4f7548119f4d7e4ed38"
      },
      "cell_type": "markdown",
      "source": "Because this is a very large dataset, it will take a long time for these algorithms to run, especially the Latent Dirichlet Allocation. To help with this, I'm going to create a smaller sub-sample of the dataset with only 1,600 news stories in it. Because I'm setting the seed, even though the sub-sampling happens randomly we'll still get the same sub-sample every time."
    },
    {
      "metadata": {
        "_cell_guid": "f8b2bdc1-981f-4b05-819a-23ee00e26d90",
        "_uuid": "f2c760c4e92af4eed7109f574783dc8e5af25206",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# subsample the dataset (so we can calculate LDA quicker)\nset.seed(1234) #setting this so we'll always get the same subset\nrow_indexes <- sample(1:nrow(texts), 1600, replace = F) # randomly generate 2000 row indexes\ntexts_subsample <-slice(english_texts, row_indexes) # get rows at those indexes\n\nhead(texts_subsample)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "824b9614-52bc-439c-8e5c-1c1ff07f9165",
        "_uuid": "ac407c148d688d5ad31f73d6c866d065fe4e4858"
      },
      "cell_type": "markdown",
      "source": "# Unsupervised topic modeling with LDA\n____\n\nNow let's use LDA to do some unsupervised topic modelling. Here, we're going to use the same function I wrote for the tutorial notebook."
    },
    {
      "metadata": {
        "_cell_guid": "d3bc4a4d-5ee8-473b-adec-847a0f7682a2",
        "_uuid": "7a14b9f62d9a692cd3a6a3d16d6ebaf737956e09",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# function to get & plot the most informative terms by a specificed number\n# of topics, using LDA\ntop_terms_by_topic_LDA <- function(input_text, # should be a columm from a dataframe\n                                   plot = T, # return a plot? TRUE by defult\n                                   number_of_topics = 4) # number of topics (4 by default)\n{    \n    # create a corpus (type of object expected by tm) and document term matrix\n    Corpus <- Corpus(VectorSource(input_text)) # make a corpus object\n    DTM <- DocumentTermMatrix(Corpus) # get the count of words/document\n\n    # remove any empty rows in our document term matrix (if there are any \n    # we'll get an error when we try to run our LDA)\n    unique_indexes <- unique(DTM$i) # get the index of each unique value\n    DTM <- DTM[unique_indexes,] # get a subset of only those indexes\n    \n    # preform LDA & get the words/topic in a tidy text format\n    lda <- LDA(DTM, k = number_of_topics, control = list(seed = 1234))\n    topics <- tidy(lda, matrix = \"beta\") # convert the LDA output to a tidy\n\n    # get the top ten terms for each topic\n    top_terms <- topics  %>% # take the topics data frame and..\n      group_by(topic) %>% # treat each topic as a different group\n      top_n(10, beta) %>% # get the top 10 most informative words\n      ungroup() %>% # ungroup\n      arrange(topic, -beta) # arrange words in descending informativeness\n\n    # if the user asks for a plot (TRUE by default)\n    if(plot == T){\n        # plot the top ten terms for each topic in order\n        top_terms %>% # take the top terms\n          mutate(term = reorder(term, beta)) %>% # sort terms by beta value \n          ggplot(aes(term, beta, fill = factor(topic))) + # plot beta by theme\n          geom_col(show.legend = FALSE) + # as a bar plot\n          facet_wrap(~ topic, scales = \"free\") + # which each topic in a seperate plot\n          labs(x = NULL, y = \"Beta\") + # no x label, change y label \n          coord_flip() # turn bars sideways\n    }else{ \n        # if the user does not request a plot\n        # return a list of sorted terms instead\n        return(top_terms)\n    }\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c3348716-57bd-4553-bdab-cf29c1f270b7",
        "_uuid": "391d89dc74da27077ceaea8e2a932b72df384f43"
      },
      "cell_type": "markdown",
      "source": "Your turn: use this function to find and plot the ten most informative words for 4 topics. **Make sure to use the texts_subsample rather than the full texts if you want this to run relatively quickly.**"
    },
    {
      "metadata": {
        "_cell_guid": "a2f3bcb3-3b5f-4a78-8897-f6f29fb50ddc",
        "_uuid": "2890f4c4ab0d50af4c59ced29b4c1ee23fd19e74",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plot top ten terms by topic \ntop_terms_by_topic_LDA(texts_subsample$text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "faed49fd-d2a0-4de4-84c5-b945642ebf29",
        "_uuid": "b91b51e32d08d7cd6eb78cdc3eba8c2c3fab47f0"
      },
      "cell_type": "markdown",
      "source": "The first three word lists mostly consist of stop words, and the fourth has many Spanish words and numbers. "
    },
    {
      "metadata": {
        "_cell_guid": "22ab9918-34fb-43b5-95cc-c262c97d6db0",
        "_uuid": "4270e90cbef1ceb652e480f708c1174ab325d155"
      },
      "cell_type": "markdown",
      "source": "# Pre-processing text for more informative models\n____\n\nNow let's do some pre-processing to this text to see how it affects our topic model. First we're going to need to do some data cleaning."
    },
    {
      "metadata": {
        "_cell_guid": "228ba78f-f356-496f-8f86-119a7ce3b725",
        "_uuid": "3d0a8bd46fe8051510eebc643bf6b79981222c1e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create a document term matrix to clean\nnewsCorpus <- Corpus(VectorSource(texts_subsample$text))\nnewsDTM <- DocumentTermMatrix(newsCorpus)\n\n# convert the document term matrix to a tidytext corpus\nnewsDTM_tidy <- tidy(newsDTM)\n\n# remove stopwords\nnewsDTM_cleaned <- newsDTM_tidy %>%\n    anti_join(stop_words, by = c(\"term\" = \"word\"))  # remove English stopwords\n\n# reconstruct cleaned documents \ncleaned_documents <- newsDTM_cleaned %>%\n    group_by(document) %>% \n    mutate(terms = toString(rep(term, count))) %>%\n    select(document, terms) %>%\n    unique()\n\nhead(cleaned_documents)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4d0f64f0-eabb-4f9a-8a28-d5326666bd6b",
        "_uuid": "d7f0b6ea915f90cd960c60a6cc899877766b9493"
      },
      "cell_type": "markdown",
      "source": "Now, rerun your LDA analysis from earlier, still with 4 topics, but this time use  the version of the dataset that has the stopwords removed."
    },
    {
      "metadata": {
        "_cell_guid": "8c2b8c14-cadd-45de-86ee-6b09740aa45c",
        "_uuid": "36eb090c42a660ac8c54fa79a0d7cb04c986779e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# take a look at the new most informative terms\ntop_terms_by_topic_LDA(cleaned_documents$terms)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "37b4f84a-7810-4b5a-9364-29a5520e51d1",
        "_uuid": "af36fc5b54f5c1b1ff36e6493451b5d98d4e2102"
      },
      "cell_type": "markdown",
      "source": "Next, let's try stemming our texts. You can use the wordStem() function from the SnowballC package. Then do LDA a third time to see the difference. Scroll back up and compare the most informative words from each model. Do you notice any differences between the models?"
    },
    {
      "metadata": {
        "_cell_guid": "6ab0e3f3-f5b5-4e73-afd2-18ba5754fca0",
        "_uuid": "25153a88dae188ec56edfb98f4a1b273e4e17037",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# stem the words (e.g. convert each word to its stem, where applicable)\nnewsDTM_cleaned <- newsDTM_cleaned %>%\n    mutate(stem = wordStem(term))\n\n# reconstruct our documents\ncleaned_documents <- newsDTM_cleaned %>%\n    group_by(document) %>% \n    mutate(terms = toString(rep(stem, count))) %>%\n    select(document, terms) %>%\n    unique()\n\n# now let's look at the new most informative terms\ntop_terms_by_topic_LDA(cleaned_documents$terms)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f8dac4f6-0291-4c31-92be-0ff0c615f304",
        "_uuid": "26a5082c501feebbb4af7c9ef6311fde8e67c44b"
      },
      "cell_type": "markdown",
      "source": "# Supervised topic modelling with TF-IDF\n___\n\nSince the texts in this dataset are labeled, let's explore them using TF-IDF. For this we can use the same function that I wrote for the tutorial. "
    },
    {
      "metadata": {
        "_cell_guid": "16794f70-3777-45d8-b6bf-ff1a3fa9d477",
        "_uuid": "d2c9a885be2020faedfd2c875fb42186355543df",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# function that takes in a dataframe and the name of the columns\n# with the document texts and the topic labels. If plot is set to\n# false it will return the tf-idf output rather than a plot.\ntop_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){\n    # name for the column we're going to unnest_tokens_ to\n    # (you only need to worry about enquo stuff if you're\n    # writing a function using using tidyverse packages)\n    group_column <- enquo(group_column)\n    text_column <- enquo(text_column)\n    \n    # get the count of each word in each review\n    words <- text_df %>%\n      unnest_tokens(word, !!text_column) %>%\n      count(!!group_column, word) %>% \n      ungroup()\n\n    # get the number of words per text\n    total_words <- words %>% \n      group_by(!!group_column) %>% \n      summarize(total = sum(n))\n\n    # combine the two dataframes we just made\n    words <- left_join(words, total_words)\n\n    # get the tf_idf & order the words by degree of relevence\n    tf_idf <- words %>%\n      bind_tf_idf(word, !!group_column, n) %>%\n      select(-total) %>%\n      arrange(desc(tf_idf)) %>%\n      mutate(word = factor(word, levels = rev(unique(word))))\n    \n    if(plot == T){\n        # convert \"group\" into a quote of a name\n        # (this is due to funkiness with calling ggplot2\n        # in functions)\n        group_name <- quo_name(group_column)\n        \n        # plot the 10 most informative terms per topic\n        tf_idf %>% \n          group_by(!!group_column) %>% \n          top_n(10) %>% \n          ungroup %>%\n          ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +\n          geom_col(show.legend = FALSE) +\n          labs(x = NULL, y = \"tf-idf\") +\n          facet_wrap(reformulate(group_name), scales = \"free\") +\n          coord_flip()\n    }else{\n        # return the entire tf_idf dataframe\n        return(tf_idf)\n    }\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2fba3345-2e25-4d86-8833-fe4863d137c8",
        "_uuid": "9c1e9a99d9cf09c88c05f610ac7392597155ce09"
      },
      "cell_type": "markdown",
      "source": "Now, use the function above to check out the most informative words for each label in the \"type\" column. If you like, since TF-IDF tends to be faster than LDA, you can use the whole dataset for this rather than the subset we used for the LDA above. "
    },
    {
      "metadata": {
        "_cell_guid": "49f19b66-0733-4a56-8379-148d9ce0fae0",
        "_uuid": "899c2d238fa705f595f8447ca5adcff0c40c3dc8",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Plot the top terms for each label in the \"type\" column.\ntop_terms_by_topic_tfidf(text_df = texts_subsample, # dataframe\n                         text_column = text, # column with text\n                         group_column = type, # column with topic label\n                         plot = T) # return a plot",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2b0f3e39-ab12-4817-b7af-8af1e587e8d5",
        "_uuid": "521ae1c9ca15b22ea81b9ca907fd9e2df8c99fbe"
      },
      "cell_type": "markdown",
      "source": "We can use the function to explore other labels as well. Can you plot the most informative words for posts from each language?"
    },
    {
      "metadata": {
        "_cell_guid": "31aa32a8-41f3-4d15-9a0f-144d128633a7",
        "_uuid": "5fa7e7048f59f6381b43002863680f13f7219346",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plot the top terms by language, using the labels in the \"language\" column\ntop_terms_by_topic_tfidf(text_df = texts, # dataframe\n                         text_column = text, # column with text\n                         group_column = language, # column with topic label\n                         plot = T) # return a plot",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2a400026-9789-4b6a-8e7b-2a287e8b1f85",
        "_uuid": "b898de59ddab836343a5360b928ceb1060808e7b"
      },
      "cell_type": "markdown",
      "source": "# Conclusion\n____\n\nAnd that's it for this tutorial! Nice work making it through all the exercises. If you're looking for more tutorials on working with text data, check these out:\n\n* [Tokenization](https://www.kaggle.com/rtatman/tokenization-tutorial) \n* [Getting n-grams](https://www.kaggle.com/rtatman/tutorial-getting-n-grams)\n* [Sentiment analysis](https://www.kaggle.com/rtatman/tutorial-sentiment-analysis-in-r/)\n\nHappy analyzing!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.4.2",
      "file_extension": ".r",
      "codemirror_mode": "r"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}